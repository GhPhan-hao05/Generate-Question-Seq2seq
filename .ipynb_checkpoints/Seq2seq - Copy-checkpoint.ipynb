{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d169f209",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n",
      "C:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\transformers\\utils\\generic.py:260: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  torch.utils._pytree._register_pytree_node(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "# from sample_squad_data import *\n",
    "# from sample_another_data import *\n",
    "import pickle\n",
    "import time\n",
    "from transformers import BertModel, BertTokenizer\n",
    "from torch.nn.utils.rnn import pad_packed_sequence\n",
    "from torch.nn.utils.rnn import pack_padded_sequence\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "273aaf50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ce2e48ec",
   "metadata": {
    "code_folding": [
     47
    ]
   },
   "outputs": [],
   "source": [
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self,input_size, hidden_size, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.rnn = nn.GRU(input_size, hidden_size, num_layers = 1,\n",
    "                          dropout= dropout, bidirectional=True, batch_first = True)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "    def forward(self, input_emb, lengths, device):\n",
    "        lengths = lengths.cpu()\n",
    "        emb = pack_padded_sequence(input_emb, lengths, batch_first=False, enforce_sorted=False)\n",
    "        self.rnn.flatten_parameters()\n",
    "        outputs, hidden_t = self.rnn(emb)\n",
    "        outputs = pad_packed_sequence(outputs, batch_first=False)\n",
    "        return outputs, hidden_t\n",
    "\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, enc_size, dec_size, n_layers, att_vec_size, bert_model_name, dropout= 0.1): \n",
    "        super().__init__()\n",
    "        self.bert = BertModel.from_pretrained(bert_model_name)\n",
    "        self.rnn = nn.GRU(\n",
    "            992, dec_size,\n",
    "            num_layers=n_layers, dropout=dropout,\n",
    "            bidirectional=False, batch_first=False) #dec_size : hidden size của GRU\n",
    "        self.attn = ConcatAttention(enc_size, dec_size, att_vec_size)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.hidden_size = dec_size\n",
    "\n",
    "    def forward(self, question_ids, hidden, context, init_attn_weighted_context):#context: decinit, init_weight = 0\n",
    "        g_outputs = []\n",
    "        c_outputs = []\n",
    "        copy_gate_outputs = []\n",
    "        current_attn_weighted_context = init_attn_weighted_context\n",
    "        precompute = None\n",
    "        with torch.no_grad():\n",
    "            word_emb = self.bert.embeddings.word_embeddings(question_ids)\n",
    "        emb_t = self.dropout(word_emb)\n",
    "        emb_t = emb_t.squeeze(1)  # emb_t shape: [batch_size, emb_dim] [32, 768]\n",
    "        decoder_rnn_input_t = emb_t # 10,768\n",
    "        decoder_rnn_input_t = torch.cat([emb_t, current_attn_weighted_context], 1).unsqueeze(0) # 768 + weight\n",
    "        output, hidden = self.rnn(decoder_rnn_input_t, hidden) #1, 32, dim----1, 32, dim\n",
    "        output= output.squeeze(0)\n",
    "        current_attn_weighted_context, attn, precompute = self.attn(output, context.transpose(0, 1), precompute)\n",
    "        return output, hidden, attn, current_attn_weighted_context\n",
    "\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, dec_size, vocab_size):\n",
    "        super(Generator, self).__init__()\n",
    "        self.generator = nn.Sequential(\n",
    "            nn.Linear(dec_size, vocab_size),\n",
    "            nn.Softmax(dim=1))\n",
    "    def forward(self, g_output_t):\n",
    "        return self.generator(g_output_t)\n",
    "    \n",
    "class ConcatAttention(nn.Module):\n",
    "    def __init__(self, context_dim, query_dim, att_dim):\n",
    "        super(ConcatAttention, self).__init__()\n",
    "        self.context_dim = context_dim\n",
    "        self.query_dim = query_dim\n",
    "        self.att_dim = att_dim\n",
    "        self.linear_pre = nn.Linear(context_dim, att_dim, bias=True)\n",
    "        self.linear_q = nn.Linear(query_dim, att_dim, bias=False)\n",
    "        self.linear_v = nn.Linear(att_dim, 1, bias=False)\n",
    "        self.sm = nn.Softmax(dim=1)\n",
    "        self.tanh = nn.Tanh()\n",
    "    def forward(self, input, context, precompute=None):\n",
    "        if precompute is None:\n",
    "            precompute00 = self.linear_pre(context.contiguous().view(-1, context.size(2))) # reshape to (..., hidden_size)\n",
    "            precompute = precompute00.view(context.size(0), context.size(1), -1)\n",
    "        targetT = self.linear_q(input).unsqueeze(1)\n",
    "        tmp10 = precompute + targetT.expand_as(precompute)\n",
    "        tmp20 = self.tanh(tmp10)\n",
    "        energy = self.linear_v(tmp20.view(-1, tmp20.size(2))).view(tmp20.size(0), tmp20.size(1))\n",
    "        score = self.sm(energy)\n",
    "        score_m = score.view(score.size(0), 1, score.size(1))\n",
    "        weightedContext = torch.bmm(score_m, context).squeeze(1)\n",
    "        return weightedContext, score, precompute\n",
    "\n",
    "class DecIniter(nn.Module):\n",
    "    def __init__(self, enc_rnn_size, dec_rnn_size):\n",
    "        super(DecIniter, self).__init__()\n",
    "        self.initer = nn.Linear(\n",
    "            enc_rnn_size,\n",
    "            dec_rnn_size)\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.linear = nn.Linear(16, enc_rnn_size//2)\n",
    "# kết hợp đầu ra encoder và style embeddinh để đưa vào decoder\n",
    "    def forward(self, enc_list):\n",
    "        enc_list[1] = self.linear(enc_list[1])#[batch, enc/2] batch, 112\n",
    "        x = torch.cat((enc_list[0], enc_list[1]), dim=1)#ini h0\n",
    "        return self.tanh(self.initer(x))  \n",
    "    \n",
    "    \n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, embedder, encoder,dec_init, decoder, generator):\n",
    "        super().__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.embedder = embedder\n",
    "        self.decIniter = dec_init\n",
    "        self.generator= generator\n",
    "        self.style_emb_mat = nn.Parameter(torch.randn(9,16))\n",
    "    def forward(self, word_emb, iob_ids, is_clue, pos_ids, ner_ids, lengths, style_ids, ques_ids, device, teacher_force):#Sample gốm data, question, style_id\n",
    "        out_length = ques_ids.shape[1]\n",
    "        style_ids = style_ids.cpu()\n",
    "        outputs = torch.zeros(out_length, ques_ids.shape[0] , 30522)#[length, batch, vocab]\n",
    "        emb = self.embedder(word_emb, iob_ids, is_clue, pos_ids, ner_ids) \n",
    "        emb = emb.transpose(0, 1)# len. batch. dim\n",
    "        context, hidden_enc = self.encoder(emb, lengths, device)# shape hidden_enc = [2, batch, hidden]\n",
    "       # context[0] : len, batch, dim\n",
    "        y_style_one_hot = torch.eye(9)[style_ids]\n",
    "        y_style_one_hot = y_style_one_hot.to(device)\n",
    "        style_emb = torch.matmul(y_style_one_hot, self.style_emb_mat)#[batch, 16]\n",
    "        hidden_0 = [hidden_enc[1], style_emb]\n",
    "        init_dec_hidden = self.decIniter(hidden_0).unsqueeze(0)\n",
    "        batch_size = context[0].size(1)  \n",
    "        h_size = (\n",
    "            batch_size,\n",
    "            112 * 2)\n",
    "        init_attn_weighted_context = context[0].data.new(*h_size).zero_()\n",
    "        current_attn_weighted_context=init_attn_weighted_context\n",
    "        hidden = init_dec_hidden\n",
    "        in_dec = ques_ids[: , 0] \n",
    "        for t in range(1, out_length):\n",
    "            out, hidden, attn, current_attn_weighted_context = self.decoder(in_dec,\n",
    "                                                                            hidden, \n",
    "                                                                            context[0],\n",
    "                                                                            current_attn_weighted_context)\n",
    "            \n",
    "            out = generator(out) #[batch, vocab]\n",
    "            outputs[t] = out\n",
    "            top1 = out.argmax(1)\n",
    "            in_dec = ques_ids[:, t] if random.random() < teacher_force else top1\n",
    "        \n",
    "        return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b116d478",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class CustomEmbedding(nn.Module):\n",
    "    def __init__(self, pos_size, ner_size,  ids_binary_emb_dim=12, out_emb= 300, dropout_rate=0.1):\n",
    "        super(CustomEmbedding, self).__init__()\n",
    "        self.iob_embedding = nn.Embedding(3, ids_binary_emb_dim)\n",
    "        self.is_clue = nn.Embedding(2, ids_binary_emb_dim)\n",
    "        self.pos_tag_embedding = nn.Embedding(pos_size, ids_binary_emb_dim)\n",
    "        self.ner_tag_embedding = nn.Embedding(ner_size, ids_binary_emb_dim)\n",
    "        \n",
    "        # Dropout layer\n",
    "        self.dropout = nn.Dropout(dropout_rate)\n",
    "        self.linear = nn.Linear(348, 300)\n",
    "        \n",
    "        \n",
    "    def forward(self, word_glove_emb, iob, is_clue, pos_tag_ids, ner_tag_ids):\n",
    "        iob_emb = self.iob_embedding(iob)\n",
    "        is_clue = self.is_clue(is_clue)\n",
    "        pos_tag_emb = self.pos_tag_embedding(pos_tag_ids)\n",
    "        ner_tag_emb = self.ner_tag_embedding(ner_tag_ids)\n",
    "        # Concatenate all embeddings\n",
    "        combined_emb = torch.cat((word_glove_emb, iob_emb, is_clue, pos_tag_emb, ner_tag_emb), dim=-1)\n",
    "        combined_emb = self.dropout(combined_emb)\n",
    "        combined_emb = combined_emb.to(torch.float32)\n",
    "        combined_emb = self.linear(combined_emb)\n",
    "        return combined_emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eedb8cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# datas = get_squad_raw_examples('train.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "781f4883",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "with open('list_ids_data1.pkl', 'rb') as file:\n",
    "    loaded_list = pickle.load(file)\n",
    "with open('token_sents.pkl', 'rb') as file:\n",
    "    token_sents = pickle.load(file)\n",
    "with open('id_big.pkl', 'rb') as file:\n",
    "    id_big = pickle.load(file)\n",
    "with open('filtered_questions.pkl', 'rb') as file:\n",
    "    filtered_questions = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a83fa29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49235"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(token_sents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "85ef975f",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ids = loaded_list\n",
    "style_ids = data_ids[0]\n",
    "pos_ids = data_ids[1]\n",
    "\n",
    "ner_ids = data_ids[2]\n",
    "iob_tag = data_ids[3]\n",
    "is_clue = data_ids[4]\n",
    "iob_ids = [[['I', 'O', 'B'].index(item) for item in iob] for iob in iob_tag]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d8b14508",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "lengths = []\n",
    "for sent in token_sents:\n",
    "    lengths.append( len(sent))\n",
    "lengths = [int(x) for x in lengths]\n",
    "lengths = torch.Tensor(lengths)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "037e5832",
   "metadata": {},
   "outputs": [],
   "source": [
    "# KHỐI CODE ĐƯỢC CMT PHÍA DƯỚI LÀ DÙNG ĐỂ LẤY DANH SÁCH EMBEDDING TỪ GLOVE VÀ LƯU VÀO FILE PICKLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "314d9a5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_token_padded = [sentence + ['<pad>'] * (80 - len(sentence)) for sentence in token_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cff558d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# special_tokens = ['<pad>', '<sos>', '<eos>']\n",
    "# def load_glove_embeddings(file_path):\n",
    "#     embeddings_index = {}\n",
    "#     with open(file_path, encoding='utf-8') as f:\n",
    "#         for line in f:\n",
    "#             values = line.split()\n",
    "#             word = values[0]\n",
    "#             coefs = np.asarray(values[1:], dtype='float32')\n",
    "#             embeddings_index[word] = coefs\n",
    "#     return embeddings_index\n",
    "\n",
    "# glove_file = './Data/glove.6B.300d.txt'  # Adjust the path to the downloaded GloVe file\n",
    "# embeddings_index = load_glove_embeddings(glove_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57200877",
   "metadata": {},
   "outputs": [],
   "source": [
    "# word_glove_emb= []\n",
    "# for sent in sent_token_padded:\n",
    "#     t =[]\n",
    "#     for word in sent:\n",
    "#         if embeddings_index.get(word.lower()) is not None:\n",
    "#             t.append(embeddings_index.get(word.lower()))\n",
    "#         elif word in special_tokens:\n",
    "#             t.append(np.zeros((300)))\n",
    "#         else:\n",
    "#             t.append(np.ones((300)))\n",
    "#     word_glove_emb.append(t)\n",
    "# # with open('glove_emb.pkl', 'wb') as file:\n",
    "# #     pickle.dump(word_glove_emb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1ef5fd08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# glove_emb_tensor1= torch.as_tensor(word_glove_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adefd799",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('glove_emb_tensor1.pkl', 'wb') as file:\n",
    "#     pickle.dump(glove_emb_tensor1, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "96e0fd4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #embedding đã được load sẵn từ glove\n",
    "with open('glove_emb_tensor1.pkl', 'rb') as file:\n",
    "    glove_emb_tensor1 = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "952e3fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "iob_ids_new = [item for idx, item in enumerate(iob_ids[0:50000]) if [idx] not in id_big]\n",
    "is_clue_new = [item for idx, item in enumerate(is_clue[0:50000]) if [idx] not in id_big]\n",
    "pos_tag_ids_new = [item for idx, item in enumerate(pos_ids[0:50000]) if [idx] not in id_big]\n",
    "ner_tag_ids_new = [item for idx, item in enumerate(ner_ids[0:50000]) if [idx] not in id_big]\n",
    "style_ids  = [item for idx, item in enumerate(style_ids[0:50000]) if [idx] not in id_big]\n",
    "# lọc ra các ids của các câu có độ dài quá lớn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "21ab6b0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a103410",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def pad_sequence(sequences, max_length):\n",
    "    padded_sequences = torch.zeros((len(sequences), max_length), dtype=torch.long)\n",
    "    for i, seq in enumerate(sequences):\n",
    "        length = min(len(seq), max_length)\n",
    "        padded_sequences[i, :length] = torch.tensor(seq[:length])\n",
    "    return padded_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4eb3b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'bert-base-uncased'\n",
    "vocab_size = 30522  \n",
    "iob_size = 3\n",
    "pos_size = 17\n",
    "ner_size = 19\n",
    "dropout_rate = 0.2\n",
    "max_length = 79\n",
    "enc_size= 224\n",
    "dec_size = 224\n",
    "n_layers = 1\n",
    "att_vec_size = 224\n",
    "input_size = 300\n",
    "hidden_size = 112\n",
    "e =10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d899ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ques = filtered_questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5e57298",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_inputs = tokenizer(ques, padding=True, truncation=True, return_tensors=\"pt\", add_special_tokens=True)\n",
    "ques_ids = tokenized_inputs['input_ids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7b0bfa61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\MY GEAR\\AppData\\Local\\Temp\\ipykernel_15940\\36262657.py:2: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  iob_ids_new = torch.tensor(pad_sequence(iob_ids_new, max_length_new))\n",
      "C:\\Users\\MY GEAR\\AppData\\Local\\Temp\\ipykernel_15940\\36262657.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  is_clue_new = torch.tensor(pad_sequence(is_clue_new, max_length_new))\n",
      "C:\\Users\\MY GEAR\\AppData\\Local\\Temp\\ipykernel_15940\\36262657.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  pos_tag_ids_new = torch.tensor(pad_sequence(pos_tag_ids_new, max_length_new))\n",
      "C:\\Users\\MY GEAR\\AppData\\Local\\Temp\\ipykernel_15940\\36262657.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  ner_tag_ids_new = torch.tensor(pad_sequence(ner_tag_ids_new, max_length_new))\n"
     ]
    }
   ],
   "source": [
    "max_length_new = 80\n",
    "iob_ids_new = torch.tensor(pad_sequence(iob_ids_new, max_length_new))\n",
    "is_clue_new = torch.tensor(pad_sequence(is_clue_new, max_length_new))\n",
    "pos_tag_ids_new = torch.tensor(pad_sequence(pos_tag_ids_new, max_length_new))\n",
    "ner_tag_ids_new = torch.tensor(pad_sequence(ner_tag_ids_new, max_length_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4889bdb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "style_ids_new = [item for sublist in style_ids for item in sublist] # style_ids_new\n",
    "style_ids_new = torch.tensor(style_ids_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "c9ec2a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:83: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
      "  warnings.warn(\"dropout option adds dropout after all but last \"\n",
      "C:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\huggingface_hub\\file_download.py:1150: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "embedding_layer = CustomEmbedding(pos_size, ner_size, dropout_rate=dropout_rate)#1\n",
    "encoder = Encoder(input_size, hidden_size)#2\n",
    "dec_init = DecIniter(enc_size, dec_size)\n",
    "decoder = Decoder(enc_size=enc_size, \n",
    "                 dec_size= dec_size, n_layers=n_layers, att_vec_size=att_vec_size, bert_model_name=bert_model_name)\n",
    "\n",
    "generator = Generator(dec_size = dec_size, vocab_size=vocab_size)\n",
    "seq2seq = Seq2Seq(embedding_layer, encoder, dec_init, decoder, generator)\n",
    "\n",
    "# model = Seq2Seq(embedding_layer, encoder, dec_init, decoder)\n",
    "# state_dict = torch.load('seq2seq_weight_1.pth')\n",
    "# model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f36f4f3",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, emb, iob, clue, pos, ner, lengths, style, ques): \n",
    "        self.emb = emb\n",
    "        self.iob = iob\n",
    "        self.clue = clue\n",
    "        self.pos = pos\n",
    "        self.ner = ner\n",
    "        self.lengths = lengths\n",
    "        self.style = style\n",
    "        self.ques = ques\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.lengths.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return (self.emb[idx], self.iob[idx], self.clue[idx], \n",
    "                self.pos[idx], self.ner[idx], self.lengths[idx], self.style[idx], self.ques[idx])\n",
    "\n",
    "dataset = CustomDataset(glove_emb_tensor1, iob_ids_new, is_clue_new, pos_tag_ids_new, ner_tag_ids_new, lengths, style_ids_new, ques_ids)\n",
    "\n",
    "# Create the dataloader with batch size of 32\n",
    "dataloader = DataLoader(dataset, batch_size=64, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4214da94",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "params = list(seq2seq.parameters())\n",
    "optimizer = optim.Adam(params, lr=0.1, weight_decay=0.1)\n",
    "num_epochs = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b2ffccef",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq = seq2seq.to(device)\n",
    "# generator=generator.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c5331e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 64 but got size 69 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[44], line 18\u001b[0m\n\u001b[0;32m     16\u001b[0m style \u001b[38;5;241m=\u001b[39m style\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     17\u001b[0m ques \u001b[38;5;241m=\u001b[39m ques\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m---> 18\u001b[0m out \u001b[38;5;241m=\u001b[39m seq2seq(emb, iob, clue, pos, ner, \u001b[38;5;28mlen\u001b[39m, style, ques, device, \u001b[38;5;241m0.2\u001b[39m)\n\u001b[0;32m     19\u001b[0m output_dim \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m     20\u001b[0m out \u001b[38;5;241m=\u001b[39m out[\u001b[38;5;241m1\u001b[39m:]\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, output_dim)\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32mC:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[41], line 124\u001b[0m, in \u001b[0;36mSeq2Seq.forward\u001b[1;34m(self, word_emb, iob_ids, is_clue, pos_ids, ner_ids, lengths, style_ids, ques_ids, device, teacher_force)\u001b[0m\n\u001b[0;32m    122\u001b[0m in_dec \u001b[38;5;241m=\u001b[39m ques_ids[: , \u001b[38;5;241m0\u001b[39m] \n\u001b[0;32m    123\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, out_length):\n\u001b[1;32m--> 124\u001b[0m     out, hidden, attn, current_attn_weighted_context \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(in_dec,\n\u001b[0;32m    125\u001b[0m                                                                     hidden, \n\u001b[0;32m    126\u001b[0m                                                                     context[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m    127\u001b[0m                                                                     current_attn_weighted_context)\n\u001b[0;32m    129\u001b[0m     out \u001b[38;5;241m=\u001b[39m generator(out) \u001b[38;5;66;03m#[batch, vocab]\u001b[39;00m\n\u001b[0;32m    130\u001b[0m     outputs[t] \u001b[38;5;241m=\u001b[39m out\n",
      "File \u001b[1;32mC:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mC:\\Users\\Admin\\envs\\machineLearning\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[41], line 38\u001b[0m, in \u001b[0;36mDecoder.forward\u001b[1;34m(self, question_ids, hidden, context, init_attn_weighted_context)\u001b[0m\n\u001b[0;32m     36\u001b[0m emb_t \u001b[38;5;241m=\u001b[39m emb_t\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m1\u001b[39m)  \u001b[38;5;66;03m# emb_t shape: [batch_size, emb_dim] [32, 768]\u001b[39;00m\n\u001b[0;32m     37\u001b[0m decoder_rnn_input_t \u001b[38;5;241m=\u001b[39m emb_t \u001b[38;5;66;03m# 10,768\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m decoder_rnn_input_t \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([emb_t, current_attn_weighted_context], \u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;66;03m# 768 + weight\u001b[39;00m\n\u001b[0;32m     39\u001b[0m output, hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrnn(decoder_rnn_input_t, hidden) \u001b[38;5;66;03m#1, 32, dim----1, 32, dim\u001b[39;00m\n\u001b[0;32m     40\u001b[0m output\u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 64 but got size 69 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "seq2seq.train()\n",
    "for epoch in range(1):\n",
    "    print(epoch)\n",
    "    i=0\n",
    "    for batch in dataloader:\n",
    "        if i %100 ==0:\n",
    "            print(i)\n",
    "        seq2seq.zero_grad()\n",
    "        emb, iob, clue, pos, ner, len, style, ques  = batch\n",
    "        emb = emb.to(device)\n",
    "        iob = iob.to(device)\n",
    "        clue = clue.to(device)\n",
    "        pos = pos.to(device)\n",
    "        ner = ner.to(device)\n",
    "        len = len.to(device)\n",
    "        style = style.to(device)\n",
    "        ques = ques.to(device)\n",
    "        out = seq2seq(emb, iob, clue, pos, ner, len, style, ques, device, 0.2)\n",
    "        output_dim = out.shape[-1]\n",
    "        out = out[1:].view(-1, output_dim).to(device)\n",
    "        ques = ques.permute(1, 0)\n",
    "        ques = ques[1:].reshape(-1)\n",
    "        loss = criterion(out, ques)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        print(loss.item())\n",
    "        i+=1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c6cadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NHƯ TRÊN MODEL KHI TRAIN 1 EPOCH MẤT HƠN 1,5 TIẾNG NHƯNG KHÔNG RA KẾT QUẢ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "4c2127c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(seq2seq.state_dict(), 'seq2seq_weight.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "d0ea8e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq2seq.eval().to(device)\n",
    "e = 10\n",
    "out = seq2seq(glove_emb_tensor1[0:e].to(device), iob_ids_new[0:e].to(device),\n",
    "              is_clue_new[0:e].to(device), pos_tag_ids_new[0:e].to(device), ner_tag_ids_new[0:e].to(device), \n",
    "              lengths[0:e].to(device), style_ids_new[0:e].to(device), ques_ids[0:e].to(device), device, 0)\n",
    "\n",
    "out = out.permute(1, 0, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7a6bd093",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 63])\n",
      "---- ['[PAD]', 'nipples', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional', 'institutional'] -----\n",
      "---- ['[PAD]', 'persians', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza', 'tending', 'gaza'] -----\n",
      "---- ['[PAD]', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish'] -----\n",
      "---- ['[PAD]', 'persians', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza'] -----\n",
      "---- ['[PAD]', 'persians', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza'] -----\n",
      "---- ['[PAD]', 'couples', 'hong', 'hong', 'hong', 'tending', 'institutional', '##李', '##ator', '##ator', '##ator', '##李', '##李', '##ens', 'institutional', '##ator', 'retains', '##李', '##ator', 'gaza', '##ens', 'institutional', '##李', '##ator', '##ens', 'institutional', '##李', '##ator', '##ens', 'institutional', '##ens', '##ator', 'institutional', 'gaza', 'amadeus', 'elongated', 'institutional', 'gaza', 'amadeus', 'elongated', 'institutional', 'gaza', 'amadeus', 'elongated', 'institutional', 'gaza', 'amadeus', 'elongated', 'institutional', 'gaza', 'amadeus', 'elongated', 'institutional', 'gaza', 'amadeus', 'elongated', 'institutional', 'gaza', 'amadeus', 'elongated', 'institutional', 'gaza', 'amadeus'] -----\n",
      "---- ['[PAD]', 'モ', '##kt', 'landfill', 'dupont', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill', 'landfill'] -----\n",
      "---- ['[PAD]', 'persians', 'persians', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza', 'gaza'] -----\n",
      "---- ['[PAD]', 'severe', '##龸', 'rowing', '##dan', 'marc', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator', '##ator'] -----\n",
      "---- ['[PAD]', '##cars', 'institutional', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish', 'yiddish'] -----\n"
     ]
    }
   ],
   "source": [
    "ids_prd = torch.argmax(out, dim = 2)\n",
    "print(ids_prd.shape)\n",
    "for sent in ids_prd:\n",
    "    tokens = tokenizer.convert_ids_to_tokens(sent)\n",
    "    print('----',tokens, '-----')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207a85c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
